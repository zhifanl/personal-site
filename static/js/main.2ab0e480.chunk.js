(this["webpackJsonppersonal-site"]=this["webpackJsonppersonal-site"]||[]).push([[0],{10:function(e,t,n){"use strict";n.r(t);var i=n(1),r=n.n(i),a=n(3),s=(n(8),n(0));var o=function(){return Object(s.jsxs)("div",{children:[Object(s.jsxs)("header",{className:"header",children:[Object(s.jsx)("h1",{children:"Tom Li - Software Development Engineer"}),Object(s.jsx)("p",{children:"Passionate about innovation, software development, and cloud computing."})]}),Object(s.jsxs)("nav",{className:"nav",children:[Object(s.jsx)("a",{href:"#home",children:"Home"}),Object(s.jsx)("a",{href:"#skills",children:"Skills"}),Object(s.jsx)("a",{href:"#experience",children:"Experience"}),Object(s.jsx)("a",{href:"#projects",children:"Projects"}),Object(s.jsx)("a",{href:"#education",children:"Education"}),Object(s.jsx)("a",{href:"#about",children:"About Me"}),Object(s.jsx)("a",{href:"#contact",children:"Contact"})]}),Object(s.jsxs)("section",{id:"home",className:"section",children:[Object(s.jsx)("h2",{children:"Welcome!"}),Object(s.jsx)("p",{children:"I'm Tom Li, a Software Engineer with a passion for designing & developing innovative solutions in the IT industry. Currently, I'm working as a Software Development Engineer at AWS in Vancouver, Canada."})]}),Object(s.jsxs)("section",{id:"skills",className:"section",children:[Object(s.jsx)("h2",{children:"Skills"}),Object(s.jsxs)("ul",{children:[Object(s.jsxs)("li",{children:[Object(s.jsx)("strong",{children:"Languages:"})," Java, Python, JavaScript, TypeScript, Golang, C++, C, Shell Script"]}),Object(s.jsxs)("li",{children:[Object(s.jsx)("strong",{children:"Frameworks & Tools:"})," Git, AWS, GCP, REST, Node.js, React.js, Redux, SQL, NoSQL, Kubernetes, Docker"]}),Object(s.jsxs)("li",{children:[Object(s.jsx)("strong",{children:"Domains:"})," Microservices, Distributed Systems, Frontend, Backend, Full-Stack, Machine Learning & AI, Software Architecture, Data Structures & Algorithms, Scalable Architecture, Unit Testing, Continuous Integration"]})]})]}),Object(s.jsxs)("section",{id:"experience",className:"section",children:[Object(s.jsx)("h2",{children:"Experience"}),Object(s.jsx)("h3",{children:"Open Source Contributor"}),Object(s.jsx)("p",{children:"06/2024 - 08/2024"}),Object(s.jsxs)("p",{children:["As an open source contributor, here are the key achievements:",Object(s.jsx)("br",{}),"- Contributed the development of a Power-Capped LLM Inference Service using Kubernetes, focusing on creating scalable and energy-efficient solutions for data centers.",Object(s.jsx)("br",{}),"- Designed solutions, delivered results under supervision of Distinguished Engineer from Red Hat.",Object(s.jsx)("br",{}),"- Implemented a custom power capping operator utilizing Kubernetes Event-Driven Autoscaling (KEDA) to optimize LLM inference service deployments based on power consumption limits.",Object(s.jsx)("br",{}),"- Used open source tool Kepler (with eBPF technology) for precise power consumption tracking of CPU and GPU resources, utilize metrics exporters for data aggregation and decision-making processes.",Object(s.jsx)("br",{}),"- Created a Slack-based alert system for real-time power consumption monitoring and a user-friendly interface using Slack slash commands for system control and limit modifications.",Object(s.jsx)("br",{}),"- Actively contributed to open-source development, participated in code reviews and issues."]}),Object(s.jsx)("h3",{children:"Research Assistant (University of Calgary)"}),Object(s.jsx)("p",{children:"04/2024 - 08/2024"}),Object(s.jsx)("p",{children:"As a researcher in the field of cloud computing and container orchestration, I spent the summer delving into cutting-edge technologies such as Kubernetes, Kepler(Kubernetes-based Efficient Power Level Exporter), KEDA under the guidance of Dr. Drew in the software engineering department. My work focused on exploring cloud-native open source software, with emphasis on Kubernetes scheduling algorithms. Additionally, I co-edited a paper that investigated existing carbon-aware Kubernetes scheduling solutions, highlighting my interest in sustainable computing practices."}),Object(s.jsx)("h3",{children:"Application Developer (S.i. Systems, representing TC Energy)"}),Object(s.jsx)("p",{children:"09/2023 - 06/2024"}),Object(s.jsxs)("p",{children:["As an Application Developer at TC Energy, I took the lead in designing and implementing a real-time asset management system using AWS Iceberg, Step Function, Lambda, SQL, Python, Pandas, Numpy, and S3. Ensuring robust and scalable data management.",Object(s.jsx)("br",{}),"Key Achievements include:",Object(s.jsx)("br",{}),"- Orchestrating automated updates for the data pipeline within AWS,",Object(s.jsx)("br",{}),"- Translated intricate engineering concepts into efficient code, ensured code was optimized and could run within the required time threshold,",Object(s.jsx)("br",{}),"- Executed the ingestion of extremely complex time series asset data, demanding unparalleled granularity. During development, I communicated effectively across cross-functional teams, engaged in clearing the roadblocks, and helped the team make sure data was accurate and trustworthy.",Object(s.jsx)("br",{}),"- Cross-functional Collaboration: Communicated between emissions engineers, facility asset data management teams, architects, and PowerBI developer. Dealt with ambiguity and solve problems together.",Object(s.jsx)("br",{}),"- Code Review and Quality Assurance: Actively participated in code review processes, ensuring high standards of code quality and maintainability. Contributed to the continuous improvement of software practices, enhancing team productivity and code reliability.",Object(s.jsx)("br",{})]}),Object(s.jsx)("h3",{children:"Software Development Engineer Intern (Amazon Web Services)"}),Object(s.jsx)("p",{children:"05/2023 - 08/2023"}),Object(s.jsxs)("p",{children:["As a SDE Intern worked at AWS Insights and Optimizations, Usage Reporting & Analytics team, here are the key achievements:",Object(s.jsx)("br",{}),"- Led the migration of AWS Cost Explorer\u2019s Reports Service, impacting over 3.8 million users globally by transitioning a legacy complex system on AWS to an improved and streamlined design called AWS Insights Preference Service (AIPS), significantly enhancing the performance of the API services for the team.",Object(s.jsx)("br",{}),"- Took the initiative, designed and developed a unique solution that utilizes distributed computing technology to help migrate large, complex NoSQL databases with millions of traffics while maintaining minimal downtime, great efficiency, and data consistency, and also is extensible to support migration of many other services. This solution is deployed to production and is being used by many senior developers at AWS.",Object(s.jsx)("br",{}),"- Streamlined operational processes, deprecating the legacy gateway, proxy, and lambda service applications by using the newly built service to integrate with existing software applications, resulting in a roughly 20% reduction in operational effort for developers to maintain the legacy pipeline.",Object(s.jsx)("br",{}),"- Actively communicated and collaborated with cross-functional teams from upstream and downstream to ensure the software system had zero downtime, preserving the integrity and accessibility of critical user data during the transition.",Object(s.jsx)("br",{}),"- Successfully conducted design document review (High-Level Design, Low-Level Design), and presented the result to the leadership and engineers.",Object(s.jsx)("br",{}),"- Code Review and Quality Assurance: Actively participated in code review processes, ensuring high standards of code quality and maintainability. Contributed to the continuous improvement of software practices."]}),Object(s.jsx)("h3",{children:"Software Engineer Intern (TC Energy)"}),Object(s.jsx)("p",{children:"01/2022 - 03/2023"}),Object(s.jsxs)("p",{children:["As a Software Developer Intern worked at Product Delivery Team",Object(s.jsx)("br",{}),"- Worked as a Data Engineer and built an automated ETL data pipeline for delivery data to the PowerBI Reporting Team, reducing redundant ETL work from 3 hours to 3 minutes for each AWS IceBerg table ingested in the databases (800+ different data sources in total), saving thousands of hours for Business Analysts and developers.",Object(s.jsx)("br",{}),"- Solved ambiguous and complex technical problems for TC Energy\u2019s engineers. Participated in and delivered several successful complex engineering projects involving data exploration, data collection, ingestion, data engineering, front-end development, back-end development, and data visualization by using AWS, Azure, Microsoft Fabric, React, Node, TypeScript, Python, SQL, and PowerBI.",Object(s.jsx)("br",{}),"- Developed a real-time power trading price prediction system at TC Energy. It is used by traders to forecast future prices.",Object(s.jsx)("br",{}),"- Worked as a Data Engineer to develop data feeding functions for fetching data from power market websites, then ingested ERCOT and Alberta Power Market data to AWS Redshift periodically.",Object(s.jsx)("br",{}),"- Received positive feedback from stakeholders for my performance and results that exceeded expectations."]}),Object(s.jsx)("h3",{children:"Software Engineer Intern (AI Shading)"}),Object(s.jsx)("p",{children:"06/2021 - 12/2021"}),Object(s.jsx)("p",{children:"Led the development of an AI-powered IoT curtain product using NodeRED, JavaScript, Linux, MQTT, and TensorFlow."})]}),Object(s.jsxs)("section",{id:"projects",className:"section",children:[Object(s.jsx)("h2",{children:"Projects"}),Object(s.jsx)("h3",{children:Object(s.jsx)("a",{href:"https://github.com/Climatik-Project/Climatik-Project",target:"_blank",rel:"noopener noreferrer",children:"Climatik Project"})}),Object(s.jsx)("p",{children:"Enabled LLM-powered autoscaling to scale replicas based on power capping limits, current power consumption, and forecast power consumption. Tech Stack: Golang, Kubernetes, KEDA, Python, Prometheus, Webhooks, CI/CD, Docker."}),Object(s.jsx)("h3",{children:Object(s.jsx)("a",{children:"LockedIn (Private - NDA)"})}),Object(s.jsx)("p",{children:"Developed an advanced autonomous navigation software for vehicle operators, featuring dynamic route optimization with A* algorithm and intelligent collision avoidance using C++, Shell Scripts, and QT."}),Object(s.jsx)("h3",{children:Object(s.jsx)("a",{href:"https://github.com/zhifanl/UofC-AI-Study-Hub",target:"_blank",rel:"noopener noreferrer",children:"AI Study Hub"})}),Object(s.jsx)("p",{children:"Co-developed an award-winning educational chat platform integrating Generative AI to enhance student learning, built with React, Node.js, Socket.io, MongoDB, and AWS technologies."})]}),Object(s.jsxs)("section",{id:"education",className:"section",children:[Object(s.jsx)("h2",{children:"Education"}),Object(s.jsx)("p",{children:Object(s.jsx)("strong",{children:"Bachelor of Science in Software Engineering"})}),Object(s.jsx)("p",{children:"University of Calgary (09/2019 - 04/2024) - Graduated with distinction, GPA: 3.86/4.00."})]}),Object(s.jsxs)("section",{id:"about",className:"section",children:[Object(s.jsx)("h2",{children:"About Me"}),Object(s.jsx)("p",{children:"Long story short, I was born in China and moved to Calgary 10 years ago. After graduating from the University of Calgary, I joined Amazon as a Software Development Engineer. Outside of work, I enjoy playing badminton, reading, cooking, working out, swimming, and running. I also have a 7-year-old cat named Mika."})]}),Object(s.jsxs)("section",{id:"contact",className:"section",children:[Object(s.jsx)("h2",{children:"Contact"}),Object(s.jsxs)("p",{children:["Email: ",Object(s.jsx)("a",{href:"mailto:zhifanli2000@gmail.com",children:"zhifanli2000@gmail.com"})]}),Object(s.jsxs)("p",{children:["LinkedIn: ",Object(s.jsx)("a",{href:"https://www.linkedin.com/in/zhifan-tom-li/",target:"_blank",children:"https://www.linkedin.com/in/zhifan-tom-li/"})]}),Object(s.jsxs)("p",{children:["GitHub: ",Object(s.jsx)("a",{href:"https://github.com/zhifanl",target:"_blank",children:"https://github.com/zhifanl"})]})]}),Object(s.jsx)("footer",{className:"footer",children:Object(s.jsx)("p",{children:"\xa9 Updated in 2024."})})]})};const c=()=>Object(s.jsx)(r.a.StrictMode,{children:Object(s.jsx)(o,{})}),d=document.getElementById("root");d.hasChildNodes()?Object(a.hydrate)(Object(s.jsx)(c,{}),d):Object(a.render)(Object(s.jsx)(c,{}),d)},8:function(e,t,n){}},[[10,1,2]]]);
//# sourceMappingURL=main.2ab0e480.chunk.js.map